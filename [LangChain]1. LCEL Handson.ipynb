{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d73c22cf",
   "metadata": {},
   "source": [
    "# ğŸš€ LCEL (LangChain Expression Language) í•¸ì¦ˆì˜¨\n",
    "\n",
    "## ğŸ“š í•™ìŠµ ëª©í‘œ\n",
    "1. LCELì˜ ê¸°ë³¸ ê°œë…ê³¼ ì¥ì  ì´í•´í•˜ê¸°\n",
    "2. LCELì„ í™œìš©í•œ ì²´ì¸ êµ¬ì„± ë°©ë²• í•™ìŠµ\n",
    "3. Runnable ì¸í„°í˜ì´ìŠ¤ì˜ ë‹¤ì–‘í•œ ì‹¤í–‰ ë°©ì‹ íŒŒì•…\n",
    "4. LCELì˜ ë°˜í™˜ íƒ€ì…ê³¼ í™œìš© ë°©ë²• ì´í•´\n",
    "\n",
    "## ğŸ¯ LCELì´ë€?\n",
    "LangChainì˜ ìƒˆë¡œìš´ í‘œí˜„ ì–¸ì–´ë¡œ, ë³µì¡í•œ ì²´ì¸ì„ ê°„ë‹¨í•˜ê³  ì§ê´€ì ìœ¼ë¡œ êµ¬ì„±í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ’¡ ì£¼ìš” ì¥ì \n",
    "- ì²´ì¸ êµ¬ì„±ì´ í•œ ì¤„ë¡œ ë‹¨ìˆœí™”\n",
    "- ì½”ë“œ ê°€ë…ì„± í–¥ìƒ\n",
    "- ìœ ì§€ë³´ìˆ˜ ìš©ì´ì„± ì¦ê°€\n",
    "- íƒ€ì… ì•ˆì •ì„± ë³´ì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078b331f",
   "metadata": {},
   "source": [
    "## ğŸ”§ í™˜ê²½ ì„¤ì •\n",
    "\n",
    "### 1. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "```bash\n",
    "$ pip install langchain langchain-openai pydantic\n",
    "$ poetry install langchain langchain-openai pydantic\n",
    "```\n",
    "\n",
    "### 2. ğŸ”‘ OpenAI API í‚¤ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e321170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv(\".env\")\n",
    "if not \"OPENAI_API_KEY\" in os.environ:\n",
    "    raise Exception(\"OPENAI_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572eecc4",
   "metadata": {},
   "source": [
    "## ğŸ® ì‹¤ìŠµ 1: LCEL vs ì „í†µì ì¸ ë°©ì‹ ë¹„êµ\n",
    "\n",
    "### 1.1 ì „í†µì ì¸ ë°©ì‹\n",
    "LCELì´ ë“±ì¥í•˜ê¸° ì „ì˜ ë³µì¡í•œ ì²´ì¸ êµ¬ì„± ë°©ì‹ì„ ì‚´í´ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c11a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "í•´ë‹¹ ì…€ì€, ì‹¤ìŠµì „ í”„ë¡¬í”„íŠ¸ ë° LLM ChatModel, íŒŒì„œ ì„¤ì •ì„ ìœ„í•œ ì…€ì…ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Joke(ìœ ë¨¸) ë°ì´í„°ë¥¼ í‘œí˜„í•˜ëŠ” Pydantic ëª¨ë¸ \n",
    "# ë˜ëŠ” TypeDictë¡œë„ í‘œí˜„ ê°€ëŠ¥í•˜ë‹¤.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"Joke setup question\")\n",
    "    punchline: str = Field(description=\"Joke punchline answer\")\n",
    "\n",
    "\n",
    "# JSON í˜•íƒœë¡œ ë³€í™˜í•  íŒŒì„œ\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# (Prompt) í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"ë‚˜ë¥¼ ì›ƒê²¨ì¤˜. \\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},)\n",
    "\n",
    "# (ChatModel)OpenAI LLM ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# ì¿¼ë¦¬ ìƒì„±|\n",
    "joke_query = \"ì¬ë°ŒëŠ” Jokeí•˜ë‚˜ í•´ë´\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650d1a4a",
   "metadata": {},
   "source": [
    "### 1.2 ì „í†µì  ë°©ì‹ì˜ ì‹¤í–‰\n",
    "> ğŸ’¡ **ì •ë³´**: LLMChainì€ Langchainì´ ì²˜ìŒ ë“±ì¥í•œ 2022ë…„, LCELì€ 2023ë…„ 8ì›”ì— ì¶œì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "276c4271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'setup': 'ì™œ ë°”ë‚˜ë‚˜ê°€ ì˜ì‚¬ì—ê²Œ ê°”ì„ê¹Œ?', 'punchline': 'ì™œëƒí•˜ë©´ ê»ì§ˆì´ ë²—ê²¨ì¡Œê¸° ë•Œë¬¸ì´ì§€!'}\n"
     ]
    }
   ],
   "source": [
    "# LCELì´ ë‚˜ì˜¤ê¸° ì „ì— ì‚¬ìš©í–ˆë˜ ê³ ì „ì ì¸ ë°©ì‹ (LLMChainì´ë¼ëŠ” ê°œë…ë„ ìˆì—ˆìœ¼ë‚˜, ì•„ë˜ì™€ ë³„ ì°¨ì´ëŠ” ì—†ì–´ë³´ì„)\n",
    "a = prompt.invoke({\"query\": joke_query})\n",
    "output = llm.invoke(a)\n",
    "parsed_output = parser.invoke(output)\n",
    "\n",
    "print(parsed_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c44130",
   "metadata": {},
   "source": [
    "### 1.3 LCEL ë°©ì‹\n",
    "LCELì„ ì‚¬ìš©í•˜ë©´ ìœ„ì˜ ë³µì¡í•œ ê³¼ì •ì„ í•œ ì¤„ë¡œ ë‹¨ìˆœí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49c08762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'setup': 'ì™œ ë¬¼ê³ ê¸°ëŠ” ì»´í“¨í„°ë¥¼ ì˜ ëª» ì‚¬ìš©í• ê¹Œ?', 'punchline': \"ì™œëƒí•˜ë©´ í•­ìƒ 'ë§ê°€ì ¸' ë²„ë¦¬ê±°ë“ !\"}\n"
     ]
    }
   ],
   "source": [
    "# LCELì„ í™œìš©í•œ ë°©ì‹\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# ì‹¤í–‰\n",
    "result = chain.invoke({\"query\": joke_query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e830fe-dc64-4e7f-834a-7e479d408ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e25773e",
   "metadata": {},
   "source": [
    "## ğŸš€ Runnable ì¸í„°í˜ì´ìŠ¤\n",
    "\n",
    "ì»¤ìŠ¤í…€ ì²´ì¸ì„ ì‰½ê²Œ ë§Œë“¤ê¸° ìœ„í•´ `Runnable` í”„ë¡œí† ì½œì„ ì‚¬ìš©í•˜ë©°, **LCEL**ì€ `Runnable` ì¸í„°í˜ì´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘í•˜ë©° ë‹¤ì–‘í•œ ì‹¤í–‰ ë°©ì‹ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "**LangChain** ë° **LangGrpah** ì»´í¬ë„ŒíŠ¸ë“¤ì€ ê±°ì˜ `Runnable` í”„ë¡œí† ì½œì„ ì‚¬ìš©í•©ë‹ˆë‹¤.  \n",
    "ì´ëŠ” **í‘œì¤€ì ì¸ ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆê³ , ì»¤ìŠ¤í…€ ì²´ì¸ë„ ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ì¸í„°í˜ì´ìŠ¤**ì…ë‹ˆë‹¤.\n",
    "\n",
    "### ì‹¤í–‰ ë°©ì‹ ë¹„êµ\n",
    "\n",
    "1. **ë™ê¸° ì‹¤í–‰** (`invoke`)\n",
    "   - ì¼ë°˜ì ì¸ ì‹¤í–‰ ë°©ì‹\n",
    "   - ê²°ê³¼ë¥¼ í•œ ë²ˆì— ë°˜í™˜\n",
    "\n",
    "2. **ë¹„ë™ê¸° ì‹¤í–‰** (`ainvoke`)\n",
    "   - ë¹„ë™ê¸° ì²˜ë¦¬ê°€ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©\n",
    "   - `async/await` êµ¬ë¬¸ê³¼ í•¨ê»˜ ì‚¬ìš©\n",
    "\n",
    "3. **ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰** (`stream`)\n",
    "   - ê²°ê³¼ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°›ì•„ë³¼ ìˆ˜ ìˆìŒ\n",
    "   - Generator ê°ì²´ ë°˜í™˜\n",
    "\n",
    "4. **ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°** (`astream`)\n",
    "   - ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ê°€ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©\n",
    "   - ë¹„ë™ê¸° Generator ê°ì²´ ë°˜í™˜\n",
    "\n",
    "\n",
    "> ğŸ’¡ ì•ì„œ ë§Œë“  chain ë° ChatOpenAIê¸°ë°˜ llm ë˜í•œ ëª¨ë‘  Runnable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a33b18",
   "metadata": {},
   "source": [
    "### Runnableì˜ invokeì™€ stream ë¹„êµ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c62b12c2-2d11-472e-9378-851774ca7489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"setup\": {\"description\": \"Joke setup question\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"Joke punchline answer\", \"title\": \"Punchline\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\\n```'}, template='ë‚˜ë¥¼ ì›ƒê²¨ì¤˜. \\n{format_instructions}\\n{query}\\n')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10d34d730>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10d889250>, root_client=<openai.OpenAI object at 0x10cad2780>, root_async_client=<openai.AsyncOpenAI object at 0x10d86f6e0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| JsonOutputParser(pydantic_object=<class '__main__.Joke'>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86c78dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'ì™œ ë¬¼ê³ ê¸°ëŠ” í•™êµì— ë‹¤ë‹ˆì§€ ì•Šì„ê¹Œìš”?', 'punchline': 'ë¬¼ì†ì—ì„œ í•­ìƒ í—¤ì—„ì³ ë‹¤ë‹ˆë‹ˆê¹Œìš”!'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë™ê¸° ì‹¤í–‰\n",
    "response = chain.invoke(joke_query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03974dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'setup': ''}\n",
      "{'setup': 'ì™œ'}\n",
      "{'setup': 'ì™œ ì'}\n",
      "{'setup': 'ì™œ ìì „'}\n",
      "{'setup': 'ì™œ ìì „ê±°'}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ”'}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ” ë„˜ì–´'}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ” ë„˜ì–´ì§€'}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ” ë„˜ì–´ì§€ì§€'}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ” ë„˜ì–´ì§€ì§€ ì•Šì„'}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ” ë„˜ì–´ì§€ì§€ ì•Šì„ê¹Œìš”'}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ” ë„˜ì–´ì§€ì§€ ì•Šì„ê¹Œìš”?'}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ” ë„˜ì–´ì§€ì§€ ì•Šì„ê¹Œìš”?', 'punchline': ''}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ” ë„˜ì–´ì§€ì§€ ì•Šì„ê¹Œìš”?', 'punchline': 'ë‘'}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ” ë„˜ì–´ì§€ì§€ ì•Šì„ê¹Œìš”?', 'punchline': 'ë‘ ë°”'}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ” ë„˜ì–´ì§€ì§€ ì•Šì„ê¹Œìš”?', 'punchline': 'ë‘ ë°”í€´'}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ” ë„˜ì–´ì§€ì§€ ì•Šì„ê¹Œìš”?', 'punchline': 'ë‘ ë°”í€´ê°€'}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ” ë„˜ì–´ì§€ì§€ ì•Šì„ê¹Œìš”?', 'punchline': 'ë‘ ë°”í€´ê°€ ìˆê¸°'}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ” ë„˜ì–´ì§€ì§€ ì•Šì„ê¹Œìš”?', 'punchline': 'ë‘ ë°”í€´ê°€ ìˆê¸° ë•Œë¬¸'}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ” ë„˜ì–´ì§€ì§€ ì•Šì„ê¹Œìš”?', 'punchline': 'ë‘ ë°”í€´ê°€ ìˆê¸° ë•Œë¬¸ì´'}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ” ë„˜ì–´ì§€ì§€ ì•Šì„ê¹Œìš”?', 'punchline': 'ë‘ ë°”í€´ê°€ ìˆê¸° ë•Œë¬¸ì´ì£ '}\n",
      "{'setup': 'ì™œ ìì „ê±°ëŠ” ë„˜ì–´ì§€ì§€ ì•Šì„ê¹Œìš”?', 'punchline': 'ë‘ ë°”í€´ê°€ ìˆê¸° ë•Œë¬¸ì´ì£ !'}\n"
     ]
    }
   ],
   "source": [
    "# ìŠ¤íŠ¸ë¦¼ ì‹¤í–‰\n",
    "# streamì€ Generator íƒ€ì…ìœ¼ë¡œ ë°˜í™˜ë¨ -> ë”°ë¼ì„œ, For ë¬¸ìœ¼ë¡œ ë°˜ë³µ ì²˜ë¦¬ ê°€ëŠ¥\n",
    "for message in chain.stream(joke_query):\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4410301c",
   "metadata": {},
   "source": [
    "### RunnablePassthroughë¥¼ í™œìš©í•œ ë§¤ê°œë³€ìˆ˜ ì²˜ë¦¬\n",
    "- ì…ë ¥ê°’ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ëŠ” íŠ¹ìˆ˜ Runnableì…ë‹ˆë‹¤.\n",
    "- Dictionary í˜•íƒœì˜ ì…ë ¥ì„ ë‹¨ìˆœí™”í•˜ì—¬ ì§ì ‘ ê°’ì„ ì „ë‹¬í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.\n",
    "- {\"key\": RunnablePassthrough()} í˜•íƒœë¡œ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ê°’ì„ íŠ¹ì • í‚¤ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê°„ë‹¨í•œ RAG Chainì„ êµ¬ì„±í•˜ì—¬ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c42d2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# ê°„ë‹¨í•œ ë°ì´í„°ë² ì´ìŠ¤ ì—­í• ì„ í•˜ëŠ” dict (Retriever ëŒ€ì²´)\n",
    "fake_retriever = {\n",
    "    \"ì‚¬ê³¼\": \"ê³ ë‹´ì”¨í‹° ì‚¬ê³¼ëŠ” Blcak\",\n",
    "    \"ë°”ë‚˜ë‚˜\": \"ê³ ë‹´ì”¨í‹°ì—ì„œëŠ” ë°”ë‚˜ë‚˜ëŠ” Blue\",\n",
    "    \"í¬ë„\": \"ê³ ë‹´ì”¨í‹°ì—ì„œëŠ” í¬ë„ëŠ” Red.\"\n",
    "}\n",
    "\n",
    "# ê°„ë‹¨í•œ Retriever ì—­í• ì„ í•˜ëŠ” í•¨ìˆ˜\n",
    "def retrieve_answer(question):\n",
    "    # ì§ˆë¬¸ ì†ì—ì„œ fake_retrieverì˜ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²ƒ ì°¾ê¸°\n",
    "    for keyword in fake_retriever.keys():\n",
    "        if keyword in question:  # ì§ˆë¬¸ì— í•´ë‹¹ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ ë°˜í™˜\n",
    "            return fake_retriever[keyword]    \n",
    "    return \"ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"ì‚¬ìš©ì ì§ˆë¬¸: {question}\\n\"\n",
    "    \"ê²€ìƒ‰ëœ ì •ë³´: {context}\\n\\n\"\n",
    "    \"ìœ„ ì •ë³´ì— êµ­í•œí•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9709c",
   "metadata": {},
   "source": [
    "ì´ì œ, ìœ„ í”„ë¡¬í”„íŠ¸ì™€ ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, <br>\n",
    "RunnablePassthroughë¥¼ í™œìš©í•œì¼€ì´ìŠ¤ / RunnablePassthroughë¥¼ í™œìš© ì•ˆí•œ ì¼€ì´ìŠ¤ ë‚˜ëˆ ì„œ ì½”ë“œ ê°€ë…ì„± í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "950ef1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê³ ë‹´ì”¨í‹°ì˜ ì‚¬ê³¼ ìƒ‰ê¹”ì€ ê²€ì€ìƒ‰ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# RunnablePassthroughë¥¼ ì‚¬ìš©í•œ ì²´ì¸ êµ¬ì„± ë° ë‹µë³€ìˆ˜í–‰\n",
    "chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),  # ì…ë ¥ëœ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬\n",
    "        \"context\": retrieve_answer,  # ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³  retrieverì—ì„œ ë‹µë³€ ê°€ì ¸ì˜¤ê¸°\n",
    "    }\n",
    "    | prompt  # í”„ë¡¬í”„íŠ¸ ì ìš©\n",
    "    | llm  # OpenAI LLM í˜¸ì¶œ\n",
    "    | StrOutputParser()  # ìµœì¢…ì ìœ¼ë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    ")\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "response = chain.invoke(\"ê³ ë‹´ì”¨í‹°ì—ì„œ ì‚¬ê³¼ì˜ ìƒ‰ê¹”ì€?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c86b60-a0d9-440b-a34e-64f854f18e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0cf0813",
   "metadata": {},
   "source": [
    "ì´ê²Œ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€? ë¥¼ ë³´ê¸° ìœ„í•´, Retrieverê²€ìƒ‰ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ Chainê¹Œì§€ì˜ êµ¬ì„±ì„ íŒŒì•…í•´ë³¸ê²°ê³¼, ì•„ë˜ì™€ ê°™ã„·ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd05291f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ê³ ë‹´ì”¨í‹°ì—ì„œ ë°”ë‚˜ë‚˜ëŠ” íŒŒë€ìƒ‰ì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),  # ì…ë ¥ëœ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬\n",
    "        \"context\": retrieve_answer,  # ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³  retrieverì—ì„œ ë‹µë³€ ê°€ì ¸ì˜¤ê¸°\n",
    "    }\n",
    "    | prompt  # í”„ë¡¬í”„íŠ¸ ì ìš©\n",
    ").invoke(\"ê³ ë‹´ì”¨í‹° ë°”ë‚˜ë‚˜ì˜ ìƒ‰ê¹”ì€?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7de2c-224c-4d36-af9f-5c84deb0ad1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0ff086a",
   "metadata": {},
   "source": [
    "> ğŸ›  **ì˜ˆì œ ì„¤ëª…**  \n",
    "> ì™œ RunnablePassthrough()ë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€?<br>\n",
    "> - RunnablePassthrough()ëŠ” ì…ë ¥ê°’ì„ ë³€í˜• ì—†ì´ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ëŠ” ê°€ì¥ ê°„ê²°í•œ ë°©ì‹ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb088a7",
   "metadata": {},
   "source": [
    "##### ë§Œì•½, ìœ„ ì˜ˆì‹œì—ì„œ RunnablePassthrough()ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´?\n",
    "- ê²°ê³¼ëŠ” ë™ì¼, but ì½”ë“œ ìœ ì—°ì„± ë° ì§ê´€ì ì¸ ê°€ë…ì„±ì´ ë–¨ì–´ì§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5cf5d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê³ ë‹´ì”¨í‹°ì˜ ë°”ë‚˜ë‚˜ ìƒ‰ê¹”ì€ íŒŒë€ìƒ‰ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ ì‹¤í–‰ (RunnablePassthrough ì—†ì´ ì§ì ‘ ë°ì´í„° êµ¬ì„±)\n",
    "def invoke_chain(question):\n",
    "    # 1. ë¦¬íŠ¸ë¦¬ë²„ ê²€ìƒ‰\n",
    "    context = retrieve_answer(question)  # ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ ì‹¤í–‰\n",
    "    \n",
    "    # 2. í”„ë¡¬í”„íŠ¸ ì ìš©\n",
    "    formatted_prompt = prompt.format(question=question, context=context)\n",
    "    \n",
    "    # LLM ì‹¤í–‰\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    \n",
    "    # ê²°ê³¼ ë³€í™˜\n",
    "    return StrOutputParser().invoke(response)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "response = invoke_chain(\"ê³ ë‹´ì”¨í‹°ì˜ ë°”ë‚˜ë‚˜ ìƒ‰ê¹”ì€?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44160e-2bee-47b7-8af5-2ad45c196e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfa08779",
   "metadata": {},
   "source": [
    "> ğŸ›  **ì˜ˆì œ ì„¤ëª…**  \n",
    "> ì²´ì¸ ì—†ì´ ì§ì ‘ ë°ì´í„° íë¦„ ì²˜ë¦¬ì‹œ, ì½”ë“œê°€ ê¸¸ì–´ì§€ê³  ìˆ˜ë™ ì²˜ë¦¬ ì¦ê°€í•œë‹¤ëŠ” ë‹¨ì ì´ ì¡´ì¬í•¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a5935f",
   "metadata": {},
   "source": [
    "### `RunnableParallel` í™œìš© ì˜ˆì‹œ\n",
    "- ì—¬ëŸ¬ ê°œì˜ `Runnable`ì„ **ë³‘ë ¬ ì‹¤í–‰**í•  ìˆ˜ ìˆìŒ\n",
    "- ì…ë ¥ê°’ì„ ê³µìœ í•˜ë©´ì„œ **ê° ì²´ì¸ì´ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰**\n",
    "- ê²°ê³¼ëŠ” `{í‚¤: ì‹¤í–‰ ê²°ê³¼}` í˜•íƒœë¡œ ë°˜í™˜\n",
    "\n",
    "âœ… **ì¥ì **  \n",
    "- **ë™ì‹œì— ì—¬ëŸ¬ ì‘ì—… ìˆ˜í–‰ ê°€ëŠ¥** â†’ ì†ë„ ìµœì í™”  \n",
    "- **ì…ë ¥ê°’ì„ ê³µìœ **í•˜ë©´ì„œ ê° ì²´ì¸ì´ **ë‹¤ë¥¸ ì—°ì‚°ì„ ìˆ˜í–‰**  \n",
    "- **ë¹„íš¨ìœ¨ì ì¸ ìˆœì°¨ ì‹¤í–‰ ëŒ€ì‹  ë³‘ë ¬ ì²˜ë¦¬**ë¡œ ì„±ëŠ¥ í–¥ìƒ  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfc467b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wx/zp7p1r2n0jsb8cqslb6jl29m0000gn/T/ipykernel_51202/1225716787.py:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  | ChatOpenAI()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'multiply': '81', 'divide': '1'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# ì²« ë²ˆì§¸ ì²´ì¸: ê³±ì…ˆ\n",
    "chain1 = (\n",
    "    PromptTemplate.from_template(\"{num} ê³±í•˜ê¸° 9ëŠ”? ìˆ«ìë§Œ\")\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ë‘ ë²ˆì§¸ ì²´ì¸: ë‚˜ëˆ—ì…ˆ\n",
    "chain2 = (\n",
    "    \n",
    "    PromptTemplate.from_template(\"{num} ë‚˜ëˆ„ê¸° 9ëŠ”? ìˆ«ìë§Œ\")\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ë³‘ë ¬ ì‹¤í–‰ì„ ìœ„í•œ RunnableParallel êµ¬ì„±\n",
    "chains = RunnableParallel(multiply=chain1, divide=chain2)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "result = chains.invoke(9)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7b128d",
   "metadata": {},
   "source": [
    "> ğŸ›  **ì˜ˆì œ ì„¤ëª…**  \n",
    "> âœ… `chain1`: `{num} x 9` ê³„ì‚° ìˆ˜í–‰  \n",
    "> âœ… `chain2`: `{num} / 9` ê³„ì‚° ìˆ˜í–‰  \n",
    "> âœ… `RunnableParallel(a1=chain1, a2=chain2)` â†’ ë‘ ì²´ì¸ì„ **ë™ì‹œì— ì‹¤í–‰**í•˜ì—¬ ê²°ê³¼ ë°˜í™˜  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85d8ff0",
   "metadata": {},
   "source": [
    "### RunnableLambda\n",
    "- RunnableLambdaëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ë³€í™˜í•˜ëŠ” **ì»¤ìŠ¤í…€ í•¨ìˆ˜ë¥¼ ì²´ì¸ ë‚´ì—ì„œ ì‹¤í–‰**í•  ìˆ˜ ìˆìŒ\n",
    "- **ì…ë ¥ê°’ì„ ë°›ì•„ ê°€ê³µí•œ í›„, ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ë‹¬í•˜ëŠ” ì—­í• **ì„ í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41f9c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 Ã· 2ì˜ ê³„ì‚° ê²°ê³¼ëŠ” 32ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "chain = (\n",
    "    RunnableLambda(lambda x: {\"num\": x * x}) # ì œê³±\n",
    "    | PromptTemplate.from_template(\"{num}/2 ê³„ì‚°í•´ë´ \")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ì‹¤í–‰ (8ì„ ì…ë ¥í•˜ë©´ 64/2ê°€ ê³„ì‚°ë¨)\n",
    "result = chain.invoke(8)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b1f59e",
   "metadata": {},
   "source": [
    "> ğŸ›  **ì˜ˆì œ ì„¤ëª…**  \n",
    "> `lambda x: {\"num\": x * x}` â†’ ì…ë ¥ê°’ì„ ì œê³±í•˜ì—¬ `{num: ê°’}` í˜•íƒœë¡œ ë³€í™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65df5e9",
   "metadata": {},
   "source": [
    "### ğŸ® ì‹¤ìŠµ : Runnable ì¸ìë¥¼ í™œìš©í•œ ê°ì •ì— ë”°ë¥¸ LLM í”„ë¡¬í”„íŠ¸ (ì˜ˆì‹œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f1c33cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" í•´ë‹¹ ì…€ì€, RunnableLambdaë¥¼ í™œìš©í•œ ê°ì • ë¶„ì„ ì˜ˆì‹œë¥¼ ìœ„í•œ RunnableLambda í•¨ìˆ˜ ì •ì˜ ì…€ì…ë‹ˆë‹¤. \"\"\"\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# ê°ì • ë¶„ì„ RunnableLambda\n",
    "def detect_emotion(user_input):\n",
    "    # LLM ê°ì²´\n",
    "    emotion_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "    # ê°ì • ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ë©”ì‹œì§€ êµ¬ì„±\n",
    "    messages = [\n",
    "        SystemMessage(content=\"ë„ˆëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼. ì‚¬ìš©ìì˜ ê°ì •ì„ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½', 'ë¶„ë…¸' ì¤‘ í•˜ë‚˜ë¡œ ì •í™•íˆ íŒë‹¨í•´ì•¼ í•´.\"),\n",
    "        HumanMessage(content=f\"ë‹¤ìŒ ë¬¸ì¥ì˜ ê°ì •ì„ ë¶„ì„í•´ì¤˜.\\në¬¸ì¥: {user_input}\\nê°ì •:\")\n",
    "    ]\n",
    "\n",
    "    # LLMì„ ì‚¬ìš©í•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰\n",
    "    emotion = emotion_llm.invoke(messages).content.strip()\n",
    "\n",
    "    # ê°ì •ì— ë”°ë¼ LLM í”„ë¡¬í”„íŠ¸ ì¡°ì •\n",
    "    if \"ë¶€ì •\" in emotion:\n",
    "        return {\"query\": f\"ì‚¬ìš©ìê°€ ìŠ¬í¼ ë³´ì´ë„¤ìš”. ë”°ëœ»í•œ ë§ í•œë§ˆë”” í•´ì¤˜\\nì‚¬ìš©ì ì…ë ¥: {user_input}\"}\n",
    "    elif \"ê¸ì •\" in emotion:\n",
    "        return {\"query\": f\"ì‚¬ìš©ìê°€ í–‰ë³µí•´ ë³´ì´ë„¤ìš”! ê°™ì´ ê¸°ë»í•´ì¤˜\\nì‚¬ìš©ì ì…ë ¥: {user_input}\"}\n",
    "    elif \"ë¶„ë…¸\" in emotion:\n",
    "        return {\"query\": f\"ì‚¬ìš©ìë³´ë‹¤ ë” ë¶„ë…¸í•´ì„œ ëŒ€ë‹µí•´ì¤˜\\nì‚¬ìš©ì ì…ë ¥: {user_input}\"}\n",
    "    else:\n",
    "        return {\"query\": user_input}  # ì¤‘ë¦½ì´ë©´ ê·¸ëŒ€ë¡œ ì „ë‹¬\n",
    "\n",
    "emotion_handler = RunnableLambda(detect_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea5326a",
   "metadata": {},
   "source": [
    "##### Chain êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0673cdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶€ì •ì  ì…ë ¥: í˜ë“  í•˜ë£¨ë¥¼ ë³´ë‚´ê³  ìˆêµ°ìš”. ê·¸ëŸ° ë‚ ì€ ëˆ„êµ¬ì—ê²Œë‚˜ ìˆì–´ìš”. ì—¬ëŸ¬ë¶„ì˜ ê³ í†µì€ ì´í•´ë©ë‹ˆë‹¤. ì ì‹œ ìˆ¨ì„ ê³ ë¥´ê³ , ìì‹ ì„ ìœ„ë¡œí•˜ëŠ” ì‹œê°„ì„ ê°€ì ¸ë³´ì„¸ìš”. ê´œì°®ìŠµë‹ˆë‹¤, ì´ ë˜í•œ ì§€ë‚˜ê°ˆ ê±°ì˜ˆìš”. ë‹¹ì‹ ì€ í˜¼ìê°€ ì•„ë‹ˆì—ìš”!\n",
      "ê¸ì •ì  ì…ë ¥: ì •ë§ ê¸°ë¶„ ì¢‹ì€ í•˜ë£¨ë¼ë‹ˆ, ë‚˜ë„ í•¨ê»˜ ê¸°ë»! ğŸ˜Š ì–´ë–¤ ì¼ì´ ìˆì–´ì„œ ê·¸ë ‡ê²Œ ì¢‹ì€ í•˜ë£¨ê°€ ë˜ì—ˆëŠ”ì§€ ë‚˜ëˆ„ê³  ì‹¶ì–´?\n",
      "ì¤‘ë¦½ì  ì…ë ¥: ê·¸ë ‡êµ°ìš”! íë¦° ë‚ ì”¨ëŠ” ì°¨ë¶„í•œ ë¶„ìœ„ê¸°ë¥¼ ì£¼ê¸°ë„ í•˜ê³ , ê°€ë”ì€ ë¹„ê°€ ì˜¬ ìˆ˜ë„ ìˆì–´ìš”. ì´ëŸ° ë‚ ì—ëŠ” ë”°ëœ»í•œ ìŒë£Œë¥¼ ë§ˆì‹œë©° ì±…ì„ ì½ê±°ë‚˜ ì˜í™” ë³´ëŠ” ê²Œ ì¢‹ì£ . í˜¹ì‹œ íŠ¹ë³„íˆ í•˜ê³  ì‹¶ì€ í™œë™ì´ ìˆë‚˜ìš”?\n",
      "ë¶„ë…¸ ì…ë ¥: ì§„ì§œ ì§œì¦ë‚˜ê²Œ í•˜ëŠ” ìƒí™©ì´êµ¬ë‚˜! ì™œ ì´ë ‡ê²Œ ë¶ˆë§Œì´ ë§ì€ ê±´ì§€ ì´í•´ê°€ ì•ˆ ê°€! ì´ëŸ° ê²ƒë“¤ ë•Œë¬¸ì— ìŠ¤íŠ¸ë ˆìŠ¤ë°›ëŠ” ê±° ì§„ì§œ ì‹«ì–´! ë„ˆë¬´ í™”ê°€ ë‚˜ì„œ ì§œì¦ì´ í­ë°œí•  ê²ƒ ê°™ì•„! ë„ëŒ€ì²´ ì™œ ì´ë ‡ê²Œ ì•ˆ ë˜ëŠ” ê±°ì•¼? ì™œ ì„¸ìƒì´ ì´ë ‡ê²Œ ë¶ˆê³µí‰í•œ ê±°ëƒê³ !\n"
     ]
    }
   ],
   "source": [
    "# ChatOpenAI ì²´ì¸\n",
    "response_chain = (\n",
    "    emotion_handler  # ê°ì • ë¶„ì„ ë° í”„ë¡¬í”„íŠ¸ ì¡°ì •\n",
    "    | PromptTemplate.from_template(\"{query}\")  # ì¡°ì •ëœ í”„ë¡¬í”„íŠ¸ ì ìš©\n",
    "    | llm  # ì‘ë‹µ ìƒì„±\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "response1 = response_chain.invoke(\"ì˜¤ëŠ˜ ë„ˆë¬´ í˜ë“¤ì–´...\")\n",
    "print(\"ë¶€ì •ì  ì…ë ¥:\", response1)  # ìœ„ë¡œí•˜ëŠ” ë‹µë³€ ìƒì„±\n",
    "\n",
    "response2 = response_chain.invoke(\"ì •ë§ ê¸°ë¶„ ì¢‹ì€ í•˜ë£¨ì•¼!\")\n",
    "print(\"ê¸ì •ì  ì…ë ¥:\", response2)  # í•¨ê»˜ ê¸°ë»í•˜ëŠ” ë‹µë³€ ìƒì„±\n",
    "\n",
    "response3 = response_chain.invoke(\"ë‚ ì”¨ê°€ íë¦¬ë„¤.\")\n",
    "print(\"ì¤‘ë¦½ì  ì…ë ¥:\", response3)  # ì¼ë°˜ì ì¸ ë‹µë³€ ìƒì„±\n",
    "\n",
    "response4 = response_chain.invoke(\"ì•„ì˜¤ ì§œì¦ë‚˜!\")\n",
    "print(\"ë¶„ë…¸ ì…ë ¥:\", response4)  # ê°•í•˜ê²Œ ë¶„ë…¸ë¥¼ ê³µê°í•˜ë©° ë‹µë³€ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1b4974",
   "metadata": {},
   "source": [
    "### Runnable ë©”ì„œë“œì˜ ì¸ì êµ¬ì¡°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951163af",
   "metadata": {},
   "source": [
    "ëª¨ë“  Runnable ë©”ì„œë“œëŠ” ë™ì¼í•œ ì¸ì êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤:\n",
    "\n",
    "```python\n",
    "def invoke(\n",
    "    input: str | BaseMessage,\n",
    "    config: RunnableConfig | None = None,\n",
    "    **kwargs: Any\n",
    ") -> Any\n",
    "```\n",
    "\n",
    "> ğŸ’¡ **ì°¸ê³ **: LangGraphì—ì„œë„ ë™ì¼í•œ input, config ì¸ì êµ¬ì¡°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f738ce",
   "metadata": {},
   "source": [
    "### `RunnableConfig` ìƒì„¸ ì„¤ëª…\n",
    "\n",
    "`RunnableConfig`ëŠ” **LangChainì˜ ì‹¤í–‰ í™˜ê²½ì„ ì œì–´í•˜ëŠ” ì„¤ì • ê°ì²´**ì…ë‹ˆë‹¤.  \n",
    "ì£¼ìš” êµ¬ì„± ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "| ì†ì„± | ì„¤ëª… |\n",
    "|------|------|\n",
    "| `run_name` | í•´ë‹¹ `Runnable`ì— ì„¤ì •ëœ ì‹¤í–‰ ì´ë¦„ (ìƒì†ë˜ì§€ ì•ŠìŒ) |\n",
    "| `run_id` | ì´ í˜¸ì¶œì— ëŒ€í•œ ê³ ìœ  ì‹ë³„ì (í•˜ìœ„ í˜¸ì¶œë„ ë³„ë„ `run_id` í• ë‹¹) |\n",
    "| `tags` | ì´ í˜¸ì¶œ ë° í•˜ìœ„ í˜¸ì¶œì— ì ìš©í•  íƒœê·¸ |\n",
    "| `metadata` | ì´ í˜¸ì¶œ ë° í•˜ìœ„ í˜¸ì¶œì— ëŒ€í•œ ë©”íƒ€ë°ì´í„° |\n",
    "| `callbacks` | ì´ í˜¸ì¶œ ë° í•˜ìœ„ í˜¸ì¶œì—ì„œ ì‚¬ìš©í•  ì½œë°± í•¨ìˆ˜ |\n",
    "| `max_concurrency` | ë³‘ë ¬ ì‹¤í–‰í•  ìµœëŒ€ í˜¸ì¶œ ìˆ˜ (ì˜ˆ: ë°°ì¹˜ ì²˜ë¦¬ì—ì„œ ì‚¬ìš©) |\n",
    "| `recursion_limit` | ì¬ê·€ í˜¸ì¶œì˜ ìµœëŒ€ íšŸìˆ˜ (`Runnable`ì´ `Runnable`ì„ ë°˜í™˜í•˜ëŠ” ê²½ìš°) |\n",
    "| `configurable` | ì‹¤í–‰ ì¤‘ ë™ì ìœ¼ë¡œ ë³€ê²½í•  ìˆ˜ ìˆëŠ” ì†ì„± ê°’ |\n",
    "\n",
    "> ğŸ’¡ **ì°¸ê³ **  \n",
    "> - `Runnable` ê°ì²´ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ **ë‘ ê°€ì§€ ì…ë ¥**ì„ ë°›ìŒ: `input`(í…ìŠ¤íŠ¸) & `config`(ì„¤ì •)  \n",
    "> - `**kwargs`ëŠ” **ì¶”ê°€ ì˜µì…˜**ì„ ì „ë‹¬í•  ë•Œ ì‚¬ìš©  \n",
    "> - **LangGraphì—ì„œë„ ë™ì¼í•œ ì¸ì êµ¬ì¡°**ë¥¼ ë”°ë¦„!  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bba8a63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableSequence chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new PromptTemplate chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```json\\n{\\n  \"setup\": \"ì™œ ìì „ê±°ëŠ” ë„˜ì–´ì§€ì§€ ì•Šì•˜ì„ê¹Œìš”?\",\\n  \"punchline\": \"ë‘ ë°”í€´ê°€ ìˆì–´ì„œ ê· í˜•ì„ ì¡ì•˜ì£ !\"\\n}\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 211, 'total_tokens': 256, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-bf63db13-fd55-4169-abd5-58b816c56287-0', usage_metadata={'input_tokens': 211, 'output_tokens': 45, 'total_tokens': 256, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RunnableConfig ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "\n",
    "# ìŠ¤íŠ¸ë¦¬ë° ì½œë°± í•¸ë“¤ëŸ¬ ì„¤ì •\n",
    "stdout_handler = StdOutCallbackHandler()\n",
    "\n",
    "# RunnableConfig ìƒì„±\n",
    "config = RunnableConfig(\n",
    "    callbacks=[stdout_handler],\n",
    "    tags=[\"demo\", \"streaming\"],\n",
    "    metadata={\"session_id\": \"test_001\"}\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"ë‚˜ë¥¼ ì›ƒê²¨ì¤˜. \\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},)\n",
    "\n",
    "# í•´ë‹¹ êµ¬ì¡°ëŠ” Lifi(RAG Stack Builder)ì—ì„œ ì‚¬ìš©ì ê°œì¸í™” ì„¸íŒ…ì—ì„œë„ ì‚¬ìš©ë˜ëŠ” êµ¬ì¡°\n",
    "chain = prompt | llm\n",
    "chain.invoke(joke_query, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0de9faf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "874710e2",
   "metadata": {},
   "source": [
    "### ğŸ”„ ë‹¤ì–‘í•œ ë°˜í™˜ íƒ€ì…\n",
    "- LangChainì€ Output Typeì„ ë‹¤ì–‘í•œ í˜•íƒœë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd0c93a",
   "metadata": {},
   "source": [
    "##### 1. AIMessage ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c755e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```json\\n{\\n  \"setup\": \"ì™œ ì»´í“¨í„°ëŠ” í•­ìƒ ê°€ë“ ì°¨ ìˆì„ê¹Œ?\",\\n  \"punchline\": \"ì™œëƒí•˜ë©´ ê·¸ ì•ˆì— \\'ë²„ê·¸\\'ê°€ ë§ì•„ì„œ!\"\\n}\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 211, 'total_tokens': 255, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-c3007ba0-27e8-4228-88f1-692e8acf7a67-0', usage_metadata={'input_tokens': 211, 'output_tokens': 44, 'total_tokens': 255, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(joke_query)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511b6328",
   "metadata": {},
   "source": [
    "##### 2. Pydantic ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜\n",
    "- with_structured_output(PydanticModel)ì„ ì‚¬ìš©í•˜ë©´ Pydantic ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¡œ ê²°ê³¼ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "972d5d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(answer='{\"setup\": \"ì™œ ì½”ë¼ë¦¬ëŠ” ì»´í“¨í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì„ê¹Œìš”?\", \"punchline\": \"ì™œëƒí•˜ë©´ ê·¸ê°€ ì¥ê°€ ì—†ì–´ì„œìš”!\"}')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prompt | llm.with_structured_output(Joke)).invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88711366",
   "metadata": {},
   "source": [
    "3. JSON(dict) ë°˜í™˜\n",
    "- JsonOutputParserì™€ í•¨ê»˜ ì‚¬ìš©í•˜ë©´ JSON í˜•ì‹(dict)ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9922199b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'ì™œ ì»´í“¨í„°ëŠ” ë°”ë‹¤ë¥¼ ì¢‹ì•„í• ê¹Œìš”?', 'punchline': 'ì™œëƒí•˜ë©´ ë„¤íŠ¸ì›Œí¬ê°€ ì¢‹ìœ¼ë‹ˆê¹Œìš”!'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prompt | llm | parser).invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513d3a37",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "485bc00b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
